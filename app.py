import streamlit as st
import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image, ImageDraw
import io

# Set page config
st.set_page_config(page_title="Handwritten Digit Classifier", layout="wide")

# Title
st.title("ðŸ”¢ Handwritten Digit Classifier")
st.markdown("Classify handwritten digits using a neural network trained on MNIST dataset")

# Sidebar for navigation
page = st.sidebar.radio("Select Page", ["Home", "Train Model", "Predict", "About"])

# Load or train model
@st.cache_resource
def load_or_train_model():
    """Load pre-trained model or train a new one"""
    try:
        model = keras.models.load_model('digit_model.h5')
        st.sidebar.success("âœ“ Model loaded from cache")
        return model
    except:
        st.sidebar.info("Training model...")
        # Load MNIST data
        (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()
        
        # Normalize data
        X_train = X_train / 255.0
        X_test = X_test / 255.0
        
        # Build model
        model = keras.Sequential([
            keras.layers.Flatten(input_shape=(28, 28)),
            keras.layers.Dense(100, activation='relu'),
            keras.layers.Dense(10, activation='softmax')
        ])
        
        model.compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])
        
        # Train model
        model.fit(X_train, y_train, epochs=10, verbose=0, batch_size=32)
        
        # Save model
        model.save('digit_model.h5')
        st.sidebar.success("âœ“ Model trained and saved")
        
        return model

# Load MNIST data for reference
@st.cache_data
def load_mnist_data():
    """Load MNIST dataset"""
    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    return (X_train, y_train), (X_test, y_test)

# Home page
if page == "Home":
    st.header("Welcome to the Digit Classifier!")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ðŸ“Š Project Overview")
        st.write("""
        This application uses a neural network to classify handwritten digits (0-9).
        The model is trained on the MNIST dataset, which contains 70,000 images of 
        handwritten digits.
        
        **Model Architecture:**
        - Input Layer: 784 neurons (28Ã—28 pixels)
        - Hidden Layer: 100 neurons with ReLU activation
        - Output Layer: 10 neurons with Softmax activation
        """)
    
    with col2:
        st.subheader("ðŸŽ¯ Features")
        st.write("""
        - **Train Model**: View training process and metrics
        - **Predict**: Draw or upload digits for classification
        - **Real-time Predictions**: Get instant results with confidence scores
        - **Confusion Matrix**: Analyze model performance
        """)
    
    # Display sample digits
    st.subheader("Sample MNIST Digits")
    (X_train, y_train), _ = load_mnist_data()
    
    fig, axes = plt.subplots(2, 5, figsize=(12, 5))
    for i, ax in enumerate(axes.flat):
        idx = np.random.randint(0, len(X_train))
        ax.imshow(X_train[idx], cmap='gray')
        ax.set_title(f"Label: {y_train[idx]}")
        ax.axis('off')
    st.pyplot(fig)

# Train Model page
elif page == "Train Model":
    st.header("Model Training")
    
    model = load_or_train_model()
    (X_train, y_train), (X_test, y_test) = load_mnist_data()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Model Architecture")
        st.text(model.summary())
    
    with col2:
        st.subheader("Model Performance")
        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
        st.metric("Test Accuracy", f"{accuracy*100:.2f}%")
        st.metric("Test Loss", f"{loss:.4f}")
    
    # Predictions on test set
    st.subheader("Predictions on Test Set")
    y_pred = model.predict(X_test, verbose=0)
    y_pred_labels = np.argmax(y_pred, axis=1)
    
    # Confusion matrix
    cm = tf.math.confusion_matrix(labels=y_test, predictions=y_pred_labels)
    
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
    ax.set_xlabel('Predicted')
    ax.set_ylabel('True Label')
    ax.set_title('Confusion Matrix')
    st.pyplot(fig)

# Predict page
elif page == "Predict":
    st.header("Make Predictions")
    
    model = load_or_train_model()
    
    tab1, tab2 = st.tabs(["Draw Digit", "Upload Image"])
    
    with tab1:
        st.subheader("Draw a Digit")
        st.write("Draw a digit in the canvas below (0-9)")
        
        # Create a canvas for drawing
        from streamlit_drawable_canvas import st_canvas
        
        canvas_result = st_canvas(
            fill_color="white",
            stroke_width=3,
            stroke_color="black",
            background_color="white",
            height=280,
            width=280,
            drawing_mode="freedraw",
            key="canvas",
        )
        
        if canvas_result.image_data is not None:
            # Process the drawn image
            img = Image.fromarray(canvas_result.image_data.astype('uint8'))
            img_gray = img.convert('L')
            img_resized = img_gray.resize((28, 28))
            img_array = np.array(img_resized) / 255.0
            
            # Make prediction
            prediction = model.predict(np.array([img_array]), verbose=0)
            predicted_digit = np.argmax(prediction[0])
            confidence = prediction[0][predicted_digit]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(img_resized, caption="Processed Image (28x28)", width=150)
            
            with col2:
                st.metric("Predicted Digit", predicted_digit)
                st.metric("Confidence", f"{confidence*100:.2f}%")
            
            # Show all probabilities
            st.subheader("Prediction Probabilities")
            fig, ax = plt.subplots()
            ax.bar(range(10), prediction[0])
            ax.set_xlabel('Digit')
            ax.set_ylabel('Probability')
            ax.set_xticks(range(10))
            st.pyplot(fig)
    
    with tab2:
        st.subheader("Upload an Image")
        uploaded_file = st.file_uploader("Choose an image", type=['jpg', 'jpeg', 'png'])
        
        if uploaded_file is not None:
            img = Image.open(uploaded_file).convert('L')
            img_resized = img.resize((28, 28))
            img_array = np.array(img_resized) / 255.0
            
            # Make prediction
            prediction = model.predict(np.array([img_array]), verbose=0)
            predicted_digit = np.argmax(prediction[0])
            confidence = prediction[0][predicted_digit]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(img_resized, caption="Processed Image (28x28)", width=150)
            
            with col2:
                st.metric("Predicted Digit", predicted_digit)
                st.metric("Confidence", f"{confidence*100:.2f}%")
            
            # Show all probabilities
            st.subheader("Prediction Probabilities")
            fig, ax = plt.subplots()
            ax.bar(range(10), prediction[0])
            ax.set_xlabel('Digit')
            ax.set_ylabel('Probability')
            ax.set_xticks(range(10))
            st.pyplot(fig)

# About page
elif page == "About":
    st.header("About This Project")
    
    st.subheader("Dataset")
    st.write("""
    **MNIST (Modified National Institute of Standards and Technology)**
    - 70,000 images of handwritten digits (0-9)
    - 60,000 training images
    - 10,000 test images
    - 28Ã—28 pixel grayscale images
    """)
    
    st.subheader("Model Details")
    st.write("""
    **Architecture:**
    - Flatten Layer: Converts 28Ã—28 images to 784-dimensional vectors
    - Dense Layer 1: 100 neurons with ReLU activation
    - Dense Layer 2: 10 neurons with Softmax activation
    
    **Training:**
    - Optimizer: Adam
    - Loss Function: Sparse Categorical Crossentropy
    - Epochs: 10
    - Batch Size: 32
    """)
    
    st.subheader("Performance")
    st.write("""
    The model achieves approximately **97.8% accuracy** on the test set.
    """)
    
    st.subheader("Technologies Used")
    st.write("""
    - **TensorFlow/Keras**: Deep learning framework
    - **Streamlit**: Web application framework
    - **NumPy**: Numerical computing
    - **Matplotlib & Seaborn**: Data visualization
    - **PIL**: Image processing
    """)
